{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from Thorfinn.Karlsefi.kb_connect import kb\n",
    "from Thorfinn.Hippo.chunkify import chunk\n",
    "from Thorfinn.Models.embedder import embedder_factory\n",
    "from Thorfinn.Hippo.utils import *\n",
    "from Thorfinn.utils import *\n",
    "from Thorfinn.Models.llm import llm_factory\n",
    "from Thorfinn.Models.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = pd.read_json('config.json')\n",
    "\n",
    "oapi_key = keys.iloc[0]['openai']\n",
    "gapi_key = keys.iloc[0]['googleai']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>In this notebook we will put together all the other notebooks to make a functional chatbot with a vecdb as its knowledgebase (all handled by Thorfinn!)</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Below turns all of the files in the example folder into chunked blocks that will make up the knowledge base</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = get_metadata(\"example_folder_for_hippo\")\n",
    "chunker = chunk(embed_provider='openai')\n",
    "knowledge_base = chunker.chunk_processing(df=metadata_df,to_embed='file_vision')\n",
    "embedder = embedder_factory.create(api_key=oapi_key,provider='openai')\n",
    "knowledge_base['embeddings'] = embedder.batch_embed(df=knowledge_base,to_embed='file_vision')\n",
    "knowledge_base.columns = knowledge_base.columns.str.lower().str.replace(' ','_')\n",
    "knowledge_base.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Next we startup the vecdb and create a new collection and load in the data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milv_connection = kb(collections=['test'])\n",
    "print(milv_connection.start_local_db())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milv_connection.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milv_connection.create_collection(collection_name='test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>We upload the knowledge base to the vecDB here</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milv_connection.upload_data(collection_name=\"test\",data=knowledge_base.to_json(orient='records'), partition='Jon_is_a_loser')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Now we vectorize the search query and do a search (we can throw the results of the search into a DataFrame for easy usage)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the embedder object we instantiated before to vectorize a search query\n",
    "search_vector = embedder.embed_string(query=\"What is an attention mechanism?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = pd.DataFrame(milv_connection.search(table_name='test',search_vector=search_vector, partitions=[\"Jon_is_a_loser\"],projected_fields=['name','file_vision']))\n",
    "search_results.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Kill the milvus standup</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milv_connection.stop_local_db(hard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
