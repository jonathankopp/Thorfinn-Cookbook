{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Needed Thorfinn imports\n",
    "from Thorfinn.Hippo.chunkify import chunk\n",
    "from Thorfinn.Models.embedder import embedder_factory\n",
    "from Thorfinn.Hippo.utils import *\n",
    "from Thorfinn.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = pd.read_json('config.json')\n",
    "\n",
    "oapi_key = keys.iloc[0]['openai']\n",
    "gapi_key = keys.iloc[0]['googleai']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Below is a test of using Thorfinn to chunk and embed a folder (create local knowledge base)</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>First thing is first, drop all of the files you want to be in your knowledge base into a folder. Then pass that folder path to the <i>get_metadata</i> function below</h4>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>First we need to get the metadata of the files in a folder:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_metadata returns a df for the metadata of all the files found within the root path passed in\n",
    "metadata_df = get_metadata(\"example_folder_for_hippo\")\n",
    "metadata_df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Next we utilize the <i><strong>chunk</strong></i> class from <strong>Thorfinn</strong> in order to chunk and embed our information</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = chunk(embed_provider='openai')\n",
    "knowledge_base = chunker.chunk_processing(df=metadata_df,to_embed='file_vision')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Lastly we embed the chunks!</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = embedder_factory.create(api_key=oapi_key,provider='openai')\n",
    "knowledge_base['embeddings'] = embedder.batch_embed(df=knowledge_base,to_embed='file_vision')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Now you have successfully created an in-memory knowledge base that can be used for in-context learning!</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
